{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VzgevkIrEgx"
   },
   "source": [
    "# SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.15.0 in ./venv/lib64/python3.7/site-packages (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in ./venv/lib64/python3.7/site-packages (from tensorflow==1.15.0) (3.18.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in ./venv/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in ./venv/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.15.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in ./venv/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.0.8)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.7/site-packages (from tensorflow==1.15.0) (3.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in ./venv/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in ./venv/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in ./venv/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in ./venv/lib64/python3.7/site-packages (from tensorflow==1.15.0) (1.12.1)\n",
      "Requirement already satisfied: gast==0.2.2 in ./venv/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in ./venv/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.36.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in ./venv/lib64/python3.7/site-packages (from tensorflow==1.15.0) (1.21.2)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in ./venv/lib/python3.7/site-packages (from tensorflow==1.15.0) (1.15.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in ./venv/lib/python3.7/site-packages (from tensorflow==1.15.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in ./venv/lib64/python3.7/site-packages (from tensorflow==1.15.0) (1.40.0)\n",
      "Requirement already satisfied: h5py in ./venv/lib64/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./venv/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./venv/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
      "Requirement already satisfied: importlib-metadata in ./venv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.8.1)\n",
      "Requirement already satisfied: cached-property in ./venv/lib/python3.7/site-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in ./venv/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/andres/Documents/2021-2/NER-wikiner/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rZ26k9hPrL-c"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import spacy\n",
    "#import spacy_spanish_lemmatizer\n",
    "\n",
    "from evaluation import precision_recall_f1\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "\n",
    "#nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WA-qFlQCJtQ3"
   },
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-2WH1IEsGf8w"
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "  \n",
    "  def read_tok_tag(s):\n",
    "    if s[-1] == '\\n':\n",
    "      s = s[:-1]\n",
    "    s = s.split('|')\n",
    "    return [s[0], s[2]]\n",
    "  def concatenate(x,y):\n",
    "    x[0] += [y[0]] \n",
    "    x[1] += [y[1]]\n",
    "    return x\n",
    "\n",
    "  with open(file_name, 'r', encoding='utf-8') as file:\n",
    "    tok = []\n",
    "    tag = []\n",
    "    for line in file:\n",
    "      tok_tag = list(map(read_tok_tag, line.split()))\n",
    "      dat = reduce(\n",
    "          concatenate, tok_tag ,[[], []]\n",
    "      )\n",
    "      if dat[0]:\n",
    "        tok += [dat[0]]\n",
    "        tag += [dat[1]]\n",
    "  return tok, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "g-yzo83ob3JC"
   },
   "outputs": [],
   "source": [
    "tok, tag = read_data('wiki_ner_utf.bio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8or9BTi5ivM_",
    "outputId": "d32a2716-47db-400b-dfa8-8e6ba29e0eb6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[El, Principado, de, Andorra, es, un, peque単o,...</td>\n",
       "      <td>[O, I-LOC, I-LOC, I-LOC, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Su, territorio, ,, con, capital, en, Andorra,...</td>\n",
       "      <td>[O, O, O, O, O, O, I-LOC, I-LOC, I-LOC, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[No, tiene, fuerzas, armadas, propias, y, su, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, I-LOC, O, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Durante, mucho, tiempo, pobre, y, aislado, ,,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Debido, a, la, fertilidad, de, las, tierras, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [El, Principado, de, Andorra, es, un, peque単o,...   \n",
       "1  [Su, territorio, ,, con, capital, en, Andorra,...   \n",
       "2  [No, tiene, fuerzas, armadas, propias, y, su, ...   \n",
       "3  [Durante, mucho, tiempo, pobre, y, aislado, ,,...   \n",
       "4  [Debido, a, la, fertilidad, de, las, tierras, ...   \n",
       "\n",
       "                                                tags  \n",
       "0  [O, I-LOC, I-LOC, I-LOC, O, O, O, O, O, O, O, ...  \n",
       "1  [O, O, O, O, O, O, I-LOC, I-LOC, I-LOC, O, O, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, I-LOC, O, I-...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-M...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'tokens': tok, 'tags':tag})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[el, Principado, de, Andorra, ser, uno, peque単...</td>\n",
       "      <td>[O, I-LOC, I-LOC, I-LOC, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[su, territorio, ,, con, capital, en, Andorra,...</td>\n",
       "      <td>[O, O, O, O, O, O, I-LOC, I-LOC, I-LOC, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[no, tener, fuerza, armada, propio, y, su, def...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, I-LOC, O, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[durante, mucho, tiempo, pobre, y, aislado, ,,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[debido, a, el, fertilidad, de, el, tierra, ,,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [el, Principado, de, Andorra, ser, uno, peque単...   \n",
       "1  [su, territorio, ,, con, capital, en, Andorra,...   \n",
       "2  [no, tener, fuerza, armada, propio, y, su, def...   \n",
       "3  [durante, mucho, tiempo, pobre, y, aislado, ,,...   \n",
       "4  [debido, a, el, fertilidad, de, el, tierra, ,,...   \n",
       "\n",
       "                                                tags  \n",
       "0  [O, I-LOC, I-LOC, I-LOC, O, O, O, O, O, O, O, ...  \n",
       "1  [O, O, O, O, O, O, I-LOC, I-LOC, I-LOC, O, O, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, I-LOC, O, I-...  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-M...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lemma(s):\n",
    "    for i in range(len(s)):\n",
    "        for token in nlp(s[i]):\n",
    "            s[i] = token.lemma_\n",
    "    return s\n",
    "\n",
    "data['tokens'] = data['tokens'].apply(get_lemma)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_test.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b3a8c42a0b56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_test.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr2list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr2list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tesis/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tesis/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tesis/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tesis/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Tesis/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_test.tsv'"
     ]
    }
   ],
   "source": [
    "#data.to_csv('train_test.tsv', sep='\\t', index=False)\n",
    "\n",
    "def str2list(s):\n",
    "    s = s.strip('][')\n",
    "    s = s.strip()\n",
    "    s = s.replace(\"'\", '')\n",
    "    s = s.replace('\"', '')\n",
    "    return s.split(', ')\n",
    "\n",
    "data = pd.read_csv('train_test.tsv', sep='\\t')\n",
    "data['tokens'] = data['tokens'].apply(str2list)\n",
    "data['tags'] = data['tags'].apply(str2list)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data_dics.pkl\", \"rb\") as f:\n",
    "    token2idx = pickle.load(f)\n",
    "    idx2token = pickle.load(f)\n",
    "    tag2idx = pickle.load(f)\n",
    "    idx2tag = pickle.load(f)\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0X-tryQ_JXom"
   },
   "source": [
    "# Stadistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_tjZmccvIFKq",
    "outputId": "b9eca147-1521-4fc7-dc8e-863996f9de86"
   },
   "outputs": [],
   "source": [
    "tags = reduce(lambda x,y: x + y , data['tags'].to_list(), [])\n",
    "tags = pd.DataFrame({'tags':tags, 'count': [1]*len(tags)})\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zTSHjWGJILT2",
    "outputId": "626eae63-6822-4763-e99b-bcd5a0fcbc41"
   },
   "outputs": [],
   "source": [
    "def remove_pre(s):\n",
    "  if s == 'O':\n",
    "    return s\n",
    "  return s[2:]\n",
    "\n",
    "tags['tags'] = tags['tags'].apply(remove_pre)\n",
    "tags = tags.groupby('tags', as_index=False).count()\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JP6r8avtIXYW"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "oJlPoGLeIYOl",
    "outputId": "d8bc1266-8b25-426b-e330-9a582df69ab3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = list(set(tags['tags'].unique()) - set('O'))\n",
    "sizes = [tags[tags['tags'] == label]['count'] for label in labels]\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['steelblue', 'royalblue', 'cornflowerblue'],\n",
    "        startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.title(r'Entities Proportion')\n",
    "plt.savefig('Img/Labels.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ys-dRgwJP-r"
   },
   "source": [
    "# Build Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "egRBuSZSJE1Z"
   },
   "outputs": [],
   "source": [
    "def build_dict(tokens_or_tags, special_tokens):\n",
    "    \"\"\"\n",
    "        tokens_or_tags: a list of lists of tokens or tags\n",
    "        special_tokens: some special tokens\n",
    "    \"\"\"\n",
    "    # Create a dictionary with default value 0\n",
    "    tok2idx = defaultdict(lambda:0)\n",
    "    idx2tok = []\n",
    "    \n",
    "    # Create mappings from tokens (or tags) to indices and vice versa.\n",
    "    # At first, add special tokens (or tags) to the dictionaries.\n",
    "    # The first special token must have index 0.\n",
    "\n",
    "    for token in special_tokens:\n",
    "      idx2tok.append(token)\n",
    "\n",
    "    # Mapping tok2idx should contain each token or tag only once. \n",
    "    # To do so, you should:\n",
    "    # 1. extract unique tokens/tags from the tokens_or_tags variable, which is not\n",
    "    #    occur in special_tokens (because they could have non-empty intersection)\n",
    "    # 2. index them (for example, you can add them into the list idx2tok\n",
    "    # 3. for each token/tag save the index into tok2idx).\n",
    "    \n",
    "    for token_or_tag_list in tokens_or_tags:\n",
    "      for token_or_tag in token_or_tag_list:\n",
    "        if token_or_tag not in idx2tok:\n",
    "          idx2tok.append(token_or_tag)\n",
    "      \n",
    "      tok2idx = {idx2tok[idx]:idx for idx in range(len(idx2tok))}\n",
    "\n",
    "    return tok2idx,idx2tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "rYJ4o38rJJbR",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "special_tokens = ['<UNK>', '<PAD>']\n",
    "special_tags = ['O']\n",
    "\n",
    "# Create dictionaries \n",
    "token2idx, idx2token = build_dict(data['tokens'].to_list(), special_tokens)\n",
    "tag2idx, idx2tag = build_dict(data['tags'], special_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dicts\n",
    "import pickle\n",
    "with open('token2idx.pkl', 'wb') as f:\n",
    "    pickle.dump(token2idx, f)\n",
    "    \n",
    "with open('idx2token.pkl', 'wb') as f:\n",
    "    pickle.dump(idx2token, f)\n",
    "\n",
    "with open('tag2idx.pkl', 'wb') as f:\n",
    "    pickle.dump(tag2idx, f)\n",
    "    \n",
    "with open('idx2tag.pkl', 'wb') as f:\n",
    "    pickle.dump(idx2tag, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('token2idx.pkl', 'rb') as f:\n",
    "    token2idx = pickle.load(f)\n",
    "    \n",
    "with open('idx2token.pkl', 'rb') as f:\n",
    "    idx2token = pickle.load(f)\n",
    "\n",
    "with open('tag2idx.pkl', 'rb') as f:\n",
    "    tag2idx = pickle.load(f)\n",
    "    \n",
    "with open('idx2tag.pkl', 'rb') as f:\n",
    "    idx2tag = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data_dics.pkl\", \"rb\") as f:\n",
    "    token2idx = pickle.load(f)\n",
    "    idx2token = pickle.load(f)\n",
    "    tag2idx = pickle.load(f)\n",
    "    idx2tag = pickle.load(f)\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "aeLNIp5iJLFJ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def words2idxs(tokens_list):\n",
    "    return [token2idx[word] for word in tokens_list]\n",
    "\n",
    "def tags2idxs(tags_list):\n",
    "    return [tag2idx[tag] for tag in tags_list]\n",
    "\n",
    "def idxs2words(idxs):\n",
    "    return [idx2token[idx] for idx in idxs]\n",
    "\n",
    "def idxs2tags(idxs):\n",
    "    return [idx2tag[idx] for idx in idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih5d4Z_oLURD"
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1mDp3YoDJLRQ"
   },
   "outputs": [],
   "source": [
    "def batches_generator(batch_size, tokens, tags,\n",
    "                      shuffle=True, allow_smaller_last_batch=True):\n",
    "    \"\"\"Generates padded batches of tokens and tags.\"\"\"\n",
    "    \n",
    "    n_samples = len(tokens)\n",
    "    if shuffle:\n",
    "        order = np.random.permutation(n_samples)\n",
    "    else:\n",
    "        order = np.arange(n_samples)\n",
    "\n",
    "    n_batches = n_samples // batch_size\n",
    "    if allow_smaller_last_batch and n_samples % batch_size:\n",
    "        n_batches += 1\n",
    "\n",
    "    for k in range(n_batches):\n",
    "        batch_start = k * batch_size\n",
    "        batch_end = min((k + 1) * batch_size, n_samples)\n",
    "        current_batch_size = batch_end - batch_start\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        max_len_token = 0\n",
    "        for idx in order[batch_start: batch_end]:\n",
    "            x_list.append(words2idxs(tokens[idx]))\n",
    "            y_list.append(tags2idxs(tags[idx]))\n",
    "            max_len_token = max(max_len_token, len(tags[idx]))\n",
    "            \n",
    "        # Fill in the data into numpy nd-arrays filled with padding indices.\n",
    "        x = np.ones([current_batch_size, max_len_token], dtype=np.int32) * token2idx['<PAD>']\n",
    "        y = np.ones([current_batch_size, max_len_token], dtype=np.int32) * tag2idx['O']\n",
    "        lengths = np.zeros(current_batch_size, dtype=np.int32)\n",
    "        for n in range(current_batch_size):\n",
    "            utt_len = len(x_list[n])\n",
    "            x[n, :utt_len] = x_list[n]\n",
    "            lengths[n] = utt_len\n",
    "            y[n, :utt_len] = y_list[n]\n",
    "        yield x, y, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2DssjNLsLYZl"
   },
   "outputs": [],
   "source": [
    "class BiLSTMModel():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HzFOo6erLbxo"
   },
   "outputs": [],
   "source": [
    "def declare_placeholders(self):\n",
    "    \"\"\"Specifies placeholders for the model.\"\"\"\n",
    "\n",
    "    # Placeholders for input and ground truth output.\n",
    "    self.input_batch = tf.placeholder(dtype=tf.int32, shape=[None, None], name='input_batch') \n",
    "    self.ground_truth_tags = tf.placeholder(dtype=tf.int32,shape=[None,None], name='ground_truth_tags')\n",
    "  \n",
    "    # Placeholder for lengths of the sequences.\n",
    "    self.lengths = tf.placeholder(dtype=tf.int32, shape=[None], name='lengths') \n",
    "    \n",
    "    # Placeholder for a dropout keep probability. If we don't feed\n",
    "    # a value for this placeholder, it will be equal to 1.0.\n",
    "    self.dropout_ph = tf.placeholder_with_default(tf.cast(1.0, tf.float32), shape=[])\n",
    "    \n",
    "    # Placeholder for a learning rate (tf.float32).\n",
    "    self.learning_rate_ph = tf.placeholder_with_default(tf.cast(0.1, tf.float32), shape=[])\n",
    "\n",
    "BiLSTMModel.__declare_placeholders = classmethod(declare_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sYFNqPMJLfd1"
   },
   "outputs": [],
   "source": [
    "def build_layers(self, vocabulary_size, embedding_dim, n_hidden_rnn, n_tags):\n",
    "    \"\"\"Specifies bi-LSTM architecture and computes logits for inputs.\"\"\"\n",
    "    \n",
    "    # Create embedding variable (tf.Variable) with dtype tf.float32\n",
    "    initial_embedding_matrix = np.random.randn(vocabulary_size, embedding_dim) / np.sqrt(embedding_dim)\n",
    "    embedding_matrix_variable = tf.Variable(initial_embedding_matrix,dtype=tf.float32)\n",
    "    \n",
    "    # Create RNN cells (for example, tf.nn.rnn_cell.BasicLSTMCell) with n_hidden_rnn number of units \n",
    "    # and dropout (tf.nn.rnn_cell.DropoutWrapper), initializing all *_keep_prob with dropout placeholder.\n",
    "    forward_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden_rnn),\n",
    "                                                 input_keep_prob=self.dropout_ph,output_keep_prob=self.dropout_ph,state_keep_prob=self.dropout_ph)\n",
    "    backward_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden_rnn),\n",
    "                                                 input_keep_prob=self.dropout_ph,output_keep_prob=self.dropout_ph,state_keep_prob=self.dropout_ph)\n",
    "\n",
    "    # Look up embeddings for self.input_batch (tf.nn.embedding_lookup).\n",
    "    # Shape: [batch_size, sequence_len, embedding_dim].\n",
    "    embeddings = tf.nn.embedding_lookup(embedding_matrix_variable, self.input_batch)\n",
    "    \n",
    "    # Pass them through Bidirectional Dynamic RNN (tf.nn.bidirectional_dynamic_rnn).\n",
    "    # Shape: [batch_size, sequence_len, 2 * n_hidden_rnn]. \n",
    "    # Also don't forget to initialize sequence_length as self.lengths and dtype as tf.float32.\n",
    "    (rnn_output_fw, rnn_output_bw), _ =  tf.nn.bidirectional_dynamic_rnn(cell_fw=forward_cell, cell_bw= backward_cell,inputs=embeddings,sequence_length=self.lengths, dtype=tf.float32)\n",
    "    rnn_output = tf.concat([rnn_output_fw, rnn_output_bw], axis=2)\n",
    "\n",
    "    # Dense layer on top.\n",
    "    # Shape: [batch_size, sequence_len, n_tags].\n",
    "    self.logits = tf.layers.dense(rnn_output, n_tags, activation=None)\n",
    "  \n",
    "BiLSTMModel.__build_layers = classmethod(build_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uN7TZuH2LiBg"
   },
   "outputs": [],
   "source": [
    "def compute_predictions(self):\n",
    "    \"\"\"Transforms logits to probabilities and finds the most probable tags.\"\"\"\n",
    "    \n",
    "    # Create softmax (tf.nn.softmax) function\n",
    "    softmax_output = tf.nn.softmax(self.logits)\n",
    "    \n",
    "    # Use argmax (tf.argmax) to get the most probable tags\n",
    "    # Don't forget to set axis=-1\n",
    "    # otherwise argmax will be calculated in a wrong way\n",
    "    self.predictions = tf.argmax(softmax_output,axis=-1)\n",
    "\n",
    "BiLSTMModel.__compute_predictions = classmethod(compute_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "l1c29-_XLmRC"
   },
   "outputs": [],
   "source": [
    "def compute_loss(self, n_tags, PAD_index):\n",
    "    \"\"\"Computes masked cross-entopy loss with logits.\"\"\"\n",
    "    \n",
    "    # Create cross entropy function function (tf.nn.softmax_cross_entropy_with_logits_v2)\n",
    "    ground_truth_tags_one_hot = tf.one_hot(self.ground_truth_tags, n_tags)\n",
    "    loss_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(ground_truth_tags_one_hot,self.logits)\n",
    "    \n",
    "    mask = tf.cast(tf.not_equal(self.input_batch, PAD_index), tf.float32)\n",
    "    # Create loss function which doesn't operate with <PAD> tokens (tf.reduce_mean)\n",
    "    # Be careful that the argument of tf.reduce_mean should be\n",
    "    # multiplication of mask and loss_tensor.\n",
    "    self.loss = tf.reduce_mean(tf.reduce_sum(tf.multiply(loss_tensor, mask),axis=-1) / tf.reduce_sum(mask,axis=-1))\n",
    "\n",
    "BiLSTMModel.__compute_loss = classmethod(compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "A3uanVueLpHY"
   },
   "outputs": [],
   "source": [
    "def perform_optimization(self):\n",
    "    \"\"\"Specifies the optimizer and train_op for the model.\"\"\"\n",
    "    \n",
    "    # Create an optimizer (tf.train.AdamOptimizer)\n",
    "    self.optimizer = tf.train.AdamOptimizer(self.learning_rate_ph)\n",
    "    self.grads_and_vars = self.optimizer.compute_gradients(self.loss)\n",
    "    \n",
    "    # Gradient clipping (tf.clip_by_norm) for self.grads_and_vars\n",
    "    # Pay attention that you need to apply this operation only for gradients \n",
    "    # because self.grads_and_vars also contains variables.\n",
    "    # list comprehension might be useful in this case.\n",
    "    clip_norm = tf.cast(1.0, tf.float32)\n",
    "    self.grads_and_vars = [[tf.clip_by_norm(gradient,clip_norm),variable] for gradient,variable in self.grads_and_vars]\n",
    "    \n",
    "    self.train_op = self.optimizer.apply_gradients(self.grads_and_vars)\n",
    "\n",
    "BiLSTMModel.__perform_optimization = classmethod(perform_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IxdnfviMLriJ"
   },
   "outputs": [],
   "source": [
    "def init_model(self, vocabulary_size, n_tags, embedding_dim, n_hidden_rnn, PAD_index):\n",
    "    self.__declare_placeholders()\n",
    "    self.__build_layers(vocabulary_size, embedding_dim, n_hidden_rnn, n_tags)\n",
    "    self.__compute_predictions()\n",
    "    self.__compute_loss(n_tags, PAD_index)\n",
    "    self.__perform_optimization()\n",
    "\n",
    "BiLSTMModel.__init__ = classmethod(init_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wsgUz9unLt2p"
   },
   "outputs": [],
   "source": [
    "def train_on_batch(self, session, x_batch, y_batch, lengths, learning_rate, dropout_keep_probability):\n",
    "    feed_dict = {self.input_batch: x_batch,\n",
    "                 self.ground_truth_tags: y_batch,\n",
    "                 self.learning_rate_ph: learning_rate,\n",
    "                 self.dropout_ph: dropout_keep_probability,\n",
    "                 self.lengths: lengths}\n",
    "    \n",
    "    session.run(self.train_op, feed_dict=feed_dict)\n",
    "    \n",
    "BiLSTMModel.train_on_batch = classmethod(train_on_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zEdNv5BeLwXD"
   },
   "outputs": [],
   "source": [
    "def predict_for_batch(self, session, x_batch, lengths):\n",
    "    feed_dict = {self.input_batch:x_batch, self.lengths:lengths}\n",
    "    predictions = session.run(self.predictions,feed_dict=feed_dict)\n",
    "    return predictions\n",
    "\n",
    "BiLSTMModel.predict_for_batch = classmethod(predict_for_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvFBNYMILyqf"
   },
   "source": [
    "#Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mRjoMkYQL3u2"
   },
   "outputs": [],
   "source": [
    "def predict_tags(model, session, token_idxs_batch, lengths):\n",
    "    \"\"\"Performs predictions and transforms indices to tokens and tags.\"\"\"\n",
    "    \n",
    "    tag_idxs_batch = model.predict_for_batch(session, token_idxs_batch, lengths)\n",
    "    \n",
    "    tags_batch, tokens_batch = [], []\n",
    "    for tag_idxs, token_idxs in zip(tag_idxs_batch, token_idxs_batch):\n",
    "        tags, tokens = [], []\n",
    "        for tag_idx, token_idx in zip(tag_idxs, token_idxs):\n",
    "            tags.append(idx2tag[tag_idx])\n",
    "            tokens.append(idx2token[token_idx])\n",
    "        tags_batch.append(tags)\n",
    "        tokens_batch.append(tokens)\n",
    "    #print(tags_batch)\n",
    "    return tags_batch, tokens_batch\n",
    "    \n",
    "    \n",
    "def eval_conll(model, session, tokens, tags, short_report=True):\n",
    "    \"\"\"Computes NER quality measures using CONLL shared task script.\"\"\"\n",
    "    \n",
    "    y_true, y_pred = [], []\n",
    "    for x_batch, y_batch, lengths in batches_generator(1, tokens, tags):\n",
    "        tags_batch, tokens_batch = predict_tags(model, session, x_batch, lengths)\n",
    "        if len(x_batch[0]) != len(tags_batch[0]):\n",
    "            raise Exception(\"Incorrect length of prediction for the input, \"\n",
    "                            \"expected length: %i, got: %i\" % (len(x_batch[0]), len(tags_batch[0])))\n",
    "        predicted_tags = []\n",
    "        ground_truth_tags = []\n",
    "        for gt_tag_idx, pred_tag, token in zip(y_batch[0], tags_batch[0], tokens_batch[0]): \n",
    "            if token != '<PAD>':\n",
    "                ground_truth_tags.append(idx2tag[gt_tag_idx])\n",
    "                predicted_tags.append(pred_tag)\n",
    "\n",
    "        # We extend every prediction and ground truth sequence with 'O' tag\n",
    "        # to indicate a possible end of entity.\n",
    "        y_true.extend(ground_truth_tags + ['O'])\n",
    "        y_pred.extend(predicted_tags + ['O'])\n",
    "    #print('y_true:', y_true)\n",
    "    results = precision_recall_f1(y_true, y_pred, print_results=True, short_report=short_report)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFX4PXN1L_CK",
    "outputId": "66608ad3-a276-42f5-d356-71e2f7248487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_26018/2351206343.py:10: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /tmp/ipykernel_26018/2351206343.py:22: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/andzap/Documents/Tesis/lib64/python3.7/site-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/andzap/Documents/Tesis/lib64/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/andzap/Documents/Tesis/lib64/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/andzap/Documents/Tesis/lib64/python3.7/site-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /tmp/ipykernel_26018/2351206343.py:27: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/andzap/Documents/Tesis/lib64/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "model = BiLSTMModel(vocabulary_size=len(token2idx),\n",
    "                    n_tags=len(tag2idx),\n",
    "                    embedding_dim=200,\n",
    "                    n_hidden_rnn=200,\n",
    "                    PAD_index=token2idx['<PAD>'])\n",
    "\n",
    "batch_size = 256\n",
    "n_epochs = 20\n",
    "learning_rate = 0.05\n",
    "learning_rate_decay = np.sqrt(2)\n",
    "dropout_keep_probability = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bYUIgMc6MCzQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['tokens'].to_list(), data['tags'].to_list(), test_size=0.1, random_state=42)\n",
    "train_tokens = X_train[:int(len(X_train) - len(X_train)/10)]\n",
    "validation_tokens = X_train[int(len(X_train) - len(X_train)/10):]\n",
    "train_tags = y_train[:int(len(y_train) - len(y_train)/10)]\n",
    "validation_tags = y_train[int(len(y_train) - len(y_train)/10):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqNqLmaMMFlC",
    "outputId": "af033395-d34d-4f44-cddf-702b53dcab99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training... \n",
      "\n",
      "-------------------- Epoch 1 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 1637730 phrases; correct: 13014.\n",
      "\n",
      "precision:  0.79%; recall:  6.55%; F1:  1.42\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 181140 phrases; correct: 1490.\n",
      "\n",
      "precision:  0.82%; recall:  6.78%; F1:  1.47\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 22:52:40.168892: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 77824000 exceeds 10% of system memory.\n",
      "2022-10-29 22:52:40.281488: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 77824000 exceeds 10% of system memory.\n",
      "2022-10-29 22:54:38.769563: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 72089600 exceeds 10% of system memory.\n",
      "2022-10-29 22:54:38.843696: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 72089600 exceeds 10% of system memory.\n",
      "2022-10-29 23:02:19.380357: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 87244800 exceeds 10% of system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Epoch 2 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 207281 phrases; correct: 161290.\n",
      "\n",
      "precision:  77.81%; recall:  81.14%; F1:  79.44\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 22735 phrases; correct: 16965.\n",
      "\n",
      "precision:  74.62%; recall:  77.24%; F1:  75.91\n",
      "\n",
      "-------------------- Epoch 3 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 205566 phrases; correct: 170190.\n",
      "\n",
      "precision:  82.79%; recall:  85.62%; F1:  84.18\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 22739 phrases; correct: 17561.\n",
      "\n",
      "precision:  77.23%; recall:  79.96%; F1:  78.57\n",
      "\n",
      "-------------------- Epoch 4 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 203052 phrases; correct: 176173.\n",
      "\n",
      "precision:  86.76%; recall:  88.63%; F1:  87.69\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 22347 phrases; correct: 17968.\n",
      "\n",
      "precision:  80.40%; recall:  81.81%; F1:  81.10\n",
      "\n",
      "-------------------- Epoch 5 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 202202 phrases; correct: 179302.\n",
      "\n",
      "precision:  88.67%; recall:  90.20%; F1:  89.43\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 22059 phrases; correct: 18053.\n",
      "\n",
      "precision:  81.84%; recall:  82.20%; F1:  82.02\n",
      "\n",
      "-------------------- Epoch 6 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 202513 phrases; correct: 181715.\n",
      "\n",
      "precision:  89.73%; recall:  91.42%; F1:  90.57\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 22113 phrases; correct: 18178.\n",
      "\n",
      "precision:  82.21%; recall:  82.77%; F1:  82.48\n",
      "\n",
      "-------------------- Epoch 7 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 201418 phrases; correct: 183677.\n",
      "\n",
      "precision:  91.19%; recall:  92.40%; F1:  91.79\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21993 phrases; correct: 18236.\n",
      "\n",
      "precision:  82.92%; recall:  83.03%; F1:  82.97\n",
      "\n",
      "-------------------- Epoch 8 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 201115 phrases; correct: 185358.\n",
      "\n",
      "precision:  92.17%; recall:  93.25%; F1:  92.70\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21961 phrases; correct: 18239.\n",
      "\n",
      "precision:  83.05%; recall:  83.04%; F1:  83.05\n",
      "\n",
      "-------------------- Epoch 9 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 200705 phrases; correct: 186735.\n",
      "\n",
      "precision:  93.04%; recall:  93.94%; F1:  93.49\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21921 phrases; correct: 18215.\n",
      "\n",
      "precision:  83.09%; recall:  82.93%; F1:  83.01\n",
      "\n",
      "-------------------- Epoch 10 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 200641 phrases; correct: 187719.\n",
      "\n",
      "precision:  93.56%; recall:  94.44%; F1:  94.00\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21993 phrases; correct: 18310.\n",
      "\n",
      "precision:  83.25%; recall:  83.37%; F1:  83.31\n",
      "\n",
      "-------------------- Epoch 11 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 200554 phrases; correct: 188615.\n",
      "\n",
      "precision:  94.05%; recall:  94.89%; F1:  94.47\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21970 phrases; correct: 18307.\n",
      "\n",
      "precision:  83.33%; recall:  83.35%; F1:  83.34\n",
      "\n",
      "-------------------- Epoch 12 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 200306 phrases; correct: 189235.\n",
      "\n",
      "precision:  94.47%; recall:  95.20%; F1:  94.84\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21969 phrases; correct: 18303.\n",
      "\n",
      "precision:  83.31%; recall:  83.34%; F1:  83.32\n",
      "\n",
      "-------------------- Epoch 13 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 200339 phrases; correct: 189706.\n",
      "\n",
      "precision:  94.69%; recall:  95.44%; F1:  95.06\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21947 phrases; correct: 18297.\n",
      "\n",
      "precision:  83.37%; recall:  83.31%; F1:  83.34\n",
      "\n",
      "-------------------- Epoch 14 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 200217 phrases; correct: 190062.\n",
      "\n",
      "precision:  94.93%; recall:  95.62%; F1:  95.27\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21974 phrases; correct: 18291.\n",
      "\n",
      "precision:  83.24%; recall:  83.28%; F1:  83.26\n",
      "\n",
      "-------------------- Epoch 15 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 200180 phrases; correct: 190348.\n",
      "\n",
      "precision:  95.09%; recall:  95.76%; F1:  95.42\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21937 phrases; correct: 18285.\n",
      "\n",
      "precision:  83.35%; recall:  83.25%; F1:  83.30\n",
      "\n",
      "-------------------- Epoch 16 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 200188 phrases; correct: 190471.\n",
      "\n",
      "precision:  95.15%; recall:  95.82%; F1:  95.48\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21957 phrases; correct: 18281.\n",
      "\n",
      "precision:  83.26%; recall:  83.24%; F1:  83.25\n",
      "\n",
      "-------------------- Epoch 17 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 200207 phrases; correct: 190717.\n",
      "\n",
      "precision:  95.26%; recall:  95.95%; F1:  95.60\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 22019 phrases; correct: 18286.\n",
      "\n",
      "precision:  83.05%; recall:  83.26%; F1:  83.15\n",
      "\n",
      "-------------------- Epoch 18 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 200152 phrases; correct: 190748.\n",
      "\n",
      "precision:  95.30%; recall:  95.96%; F1:  95.63\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21964 phrases; correct: 18280.\n",
      "\n",
      "precision:  83.23%; recall:  83.23%; F1:  83.23\n",
      "\n",
      "-------------------- Epoch 19 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 200153 phrases; correct: 190823.\n",
      "\n",
      "precision:  95.34%; recall:  96.00%; F1:  95.67\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21983 phrases; correct: 18276.\n",
      "\n",
      "precision:  83.14%; recall:  83.21%; F1:  83.17\n",
      "\n",
      "-------------------- Epoch 20 of 20 --------------------\n",
      "Train data evaluation:\n",
      "processed 2939957 tokens with 198775 phrases; found: 200156 phrases; correct: 190866.\n",
      "\n",
      "precision:  95.36%; recall:  96.02%; F1:  95.69\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 325556 tokens with 21963 phrases; found: 21973 phrases; correct: 18282.\n",
      "\n",
      "precision:  83.20%; recall:  83.24%; F1:  83.22\n",
      "\n",
      "...training finished.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#saver = tf.train.Saver()\n",
    "\n",
    "print('Start training... \\n')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # For each epoch evaluate the model on train and validation data\n",
    "    print('-' * 20 + ' Epoch {} '.format(epoch+1) + 'of {} '.format(n_epochs) + '-' * 20)\n",
    "    print('Train data evaluation:')\n",
    "    eval_conll(model, sess, train_tokens, train_tags, short_report=True)\n",
    "    print('Validation data evaluation:')\n",
    "    eval_conll(model, sess, validation_tokens, validation_tags, short_report=True)\n",
    "    \n",
    "    # Train the model\n",
    "    for x_batch, y_batch, lengths in batches_generator(batch_size, train_tokens, train_tags):\n",
    "        model.train_on_batch(sess, x_batch, y_batch, lengths, learning_rate, dropout_keep_probability)\n",
    "        \n",
    "    # Decaying the learning rate\n",
    "    learning_rate = learning_rate / learning_rate_decay\n",
    "    \n",
    "print('...training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'out/coso'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, 'out/coso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'out/saved_model.pbtxt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.write_graph(sess.graph.as_graph_def(), 'out/',\n",
    "                     'saved_model.pbtxt', as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import freeze_graph\n",
    "freeze_graph.freeze_graph('out/saved_model.pbtxt', \"\", False, \n",
    "                          './tensorflowModel.ckpt', \"output/softmax\",\n",
    "                           \"save/restore_all\", \"save/Const:0\",\n",
    "                           'frozentensorflowModel.pb', True, \"\"  \n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'out/saved_model.pb'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.write_graph(sess.graph.as_graph_def(), 'out/',\n",
    "                     'saved_model.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gF5q7m2GNtF0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train set quality: --------------------\n",
      "processed 2939957 tokens with 198775 phrases; found: 200052 phrases; correct: 190788.\n",
      "\n",
      "precision:  95.37%; recall:  95.98%; F1:  95.67\n",
      "\n",
      "\t         LOC: precision:   94.73%; recall:   95.76%; F1:   95.24; predicted:  98175\n",
      "\n",
      "\t        MISC: precision:   92.77%; recall:   93.05%; F1:   92.91; predicted:  26790\n",
      "\n",
      "\t         ORG: precision:   93.88%; recall:   93.21%; F1:   93.55; predicted:  17332\n",
      "\n",
      "\t         PER: precision:   98.11%; recall:   98.56%; F1:   98.34; predicted:  57755\n",
      "\n",
      "-------------------- Validation set quality: --------------------\n",
      "processed 325556 tokens with 21963 phrases; found: 22684 phrases; correct: 18623.\n",
      "\n",
      "precision:  82.10%; recall:  84.79%; F1:  83.42\n",
      "\n",
      "\t         LOC: precision:   82.53%; recall:   86.76%; F1:   84.59; predicted:  11420\n",
      "\n",
      "\t        MISC: precision:   68.71%; recall:   69.91%; F1:   69.31; predicted:  2969\n",
      "\n",
      "\t         ORG: precision:   74.53%; recall:   75.83%; F1:   75.18; predicted:  1869\n",
      "\n",
      "\t         PER: precision:   89.71%; recall:   90.86%; F1:   90.28; predicted:  6426\n",
      "\n",
      "-------------------- Test set quality: --------------------\n",
      "processed 361521 tokens with 24574 phrases; found: 25315 phrases; correct: 20871.\n",
      "\n",
      "precision:  82.45%; recall:  84.93%; F1:  83.67\n",
      "\n",
      "\t         LOC: precision:   82.90%; recall:   86.77%; F1:   84.79; predicted:  12590\n",
      "\n",
      "\t        MISC: precision:   67.77%; recall:   68.94%; F1:   68.35; predicted:  3360\n",
      "\n",
      "\t         ORG: precision:   77.48%; recall:   77.33%; F1:   77.41; predicted:  2118\n",
      "\n",
      "\t         PER: precision:   89.91%; recall:   91.50%; F1:   90.70; predicted:  7247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-' * 20 + ' Train set quality: ' + '-' * 20)\n",
    "train_results = eval_conll(model, sess, train_tokens, train_tags, short_report=False)\n",
    "print('-' * 20 + ' Validation set quality: ' + '-' * 20)\n",
    "validation_results = eval_conll(model, sess, validation_tokens, validation_tags, short_report=False)\n",
    "print('-' * 20 + ' Test set quality: ' + '-' * 20)\n",
    "test_results = eval_conll(model, sess, X_test, y_test, short_report=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_session.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-6EobEhdpuA"
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DIKKvHUwdoaJ"
   },
   "outputs": [],
   "source": [
    "def predict(model, session, tokens):\n",
    "    \"\"\"Computes NER quality measures using CONLL shared task script.\"\"\"\n",
    "    \n",
    "    tags = [['O']*len(tokens[0])]\n",
    "    y_true, y_pred = [], []\n",
    "    for x_batch, y_batch, lengths in batches_generator(1, tokens, tags):\n",
    "        tags_batch, tokens_batch = predict_tags(model, session, x_batch, lengths)\n",
    "        if len(x_batch[0]) != len(tags_batch[0]):\n",
    "            raise Exception(\"Incorrect length of prediction for the input, \"\n",
    "                            \"expected length: %i, got: %i\" % (len(x_batch[0]), len(tags_batch[0])))\n",
    "        predicted_tags = []\n",
    "        for gt_tag_idx, pred_tag, token in zip(y_batch[0], tags_batch[0], tokens_batch[0]): \n",
    "            if token != '<PAD>':\n",
    "                predicted_tags.append(pred_tag)\n",
    "\n",
    "        y_pred.extend(predicted_tags)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "kL3y__4JdtoM"
   },
   "outputs": [],
   "source": [
    "def print_prediction(toks, tags):\n",
    "  for t in  zip(toks, tags):\n",
    "    print(t[0], '\\t', t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LW0lEFNad0MN",
    "outputId": "c511f586-6838-444e-cd7d-74c8133d7518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ser \t O\n",
      "Thomas \t I-PER\n",
      "Alva \t I-PER\n",
      "Edison \t I-PER\n",
      "el \t O\n",
      "creador \t O\n",
      ", \t O\n",
      "adem叩s \t O\n",
      ", \t O\n",
      "del \t O\n",
      "formato \t O\n",
      "cinematogr叩fico \t O\n",
      "por \t O\n",
      "excelencia \t O\n",
      ", \t O\n",
      "el \t O\n",
      "35 \t O\n",
      "mm \t O\n",
      ", \t O\n",
      "sobre \t O\n",
      "uno \t O\n",
      "soportir \t O\n",
      "de \t O\n",
      "nitrato \t O\n",
      "de \t O\n",
      "celul坦s \t O\n",
      ". \t O\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "pred = predict(model, sess, [X_test[idx]])\n",
    "print_prediction(X_test[idx], pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2idxs(tokens_list):\n",
    "    return [token2idx[word] if word in token2idx else token2idx['<UNK>'] for word in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Paro, Nacional, ay, est叩, lindo, el, paro, No...</td>\n",
       "      <td>[Paro, Nacional, ay, estar, lindar, el, parir,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[La, gente, sabe, !, !, La, gente, entiende, !...</td>\n",
       "      <td>[La, gente, saber, !, !, La, gente, entender, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[臓, Que, belleza, !, Deja, ordenando, que, le,...</td>\n",
       "      <td>[臓, Que, belleza, !, Deja, ordenar, que, le, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Guillermo, Lasso, Si, ,, pero, vaya, a, la, A...</td>\n",
       "      <td>[Guillermo, Lasso, Si, ,, pero, ir, a, lo, Asa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Tan, falsa, esta, nota, ,, porque, el, pasado...</td>\n",
       "      <td>[Tan, falso, este, noto, ,, porque, el, pasar,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [Paro, Nacional, ay, est叩, lindo, el, paro, No...   \n",
       "1  [La, gente, sabe, !, !, La, gente, entiende, !...   \n",
       "2  [臓, Que, belleza, !, Deja, ordenando, que, le,...   \n",
       "3  [Guillermo, Lasso, Si, ,, pero, vaya, a, la, A...   \n",
       "4  [Tan, falsa, esta, nota, ,, porque, el, pasado...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  [Paro, Nacional, ay, estar, lindar, el, parir,...  \n",
       "1  [La, gente, saber, !, !, La, gente, entender, ...  \n",
       "2  [臓, Que, belleza, !, Deja, ordenar, que, le, a...  \n",
       "3  [Guillermo, Lasso, Si, ,, pero, ir, a, lo, Asa...  \n",
       "4  [Tan, falso, este, noto, ,, porque, el, pasar,...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('test.pkl', 'rb') as f:\n",
    "    tweets = pickle.load(f)\n",
    "    \n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_list(l):\n",
    "    return predict(model, sess, [l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.26866436004639s\n",
      "(2448898, 2861973)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Paro, Nacional, ay, est叩, lindo, el, paro, No...</td>\n",
       "      <td>[Paro, Nacional, ay, estar, lindar, el, parir,...</td>\n",
       "      <td>[I-ORG, I-LOC, I-LOC, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[La, gente, sabe, !, !, La, gente, entiende, !...</td>\n",
       "      <td>[La, gente, saber, !, !, La, gente, entender, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[臓, Que, belleza, !, Deja, ordenando, que, le,...</td>\n",
       "      <td>[臓, Que, belleza, !, Deja, ordenar, que, le, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Guillermo, Lasso, Si, ,, pero, vaya, a, la, A...</td>\n",
       "      <td>[Guillermo, Lasso, Si, ,, pero, ir, a, lo, Asa...</td>\n",
       "      <td>[I-PER, I-PER, I-PER, O, O, O, O, O, I-ORG, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Tan, falsa, esta, nota, ,, porque, el, pasado...</td>\n",
       "      <td>[Tan, falso, este, noto, ,, porque, el, pasar,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [Paro, Nacional, ay, est叩, lindo, el, paro, No...   \n",
       "1  [La, gente, sabe, !, !, La, gente, entiende, !...   \n",
       "2  [臓, Que, belleza, !, Deja, ordenando, que, le,...   \n",
       "3  [Guillermo, Lasso, Si, ,, pero, vaya, a, la, A...   \n",
       "4  [Tan, falsa, esta, nota, ,, porque, el, pasado...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [Paro, Nacional, ay, estar, lindar, el, parir,...   \n",
       "1  [La, gente, saber, !, !, La, gente, entender, ...   \n",
       "2  [臓, Que, belleza, !, Deja, ordenar, que, le, a...   \n",
       "3  [Guillermo, Lasso, Si, ,, pero, ir, a, lo, Asa...   \n",
       "4  [Tan, falso, este, noto, ,, porque, el, pasar,...   \n",
       "\n",
       "                                         predictions  \n",
       "0   [I-ORG, I-LOC, I-LOC, O, O, O, O, O, O, O, O, O]  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [I-PER, I-PER, I-PER, O, O, O, O, O, I-ORG, I-...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tracemalloc\n",
    "import time\n",
    "\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "tweets['predictions'] = tweets['lemmas'].apply(predict_from_list)\n",
    "predict_time = time.time() - start_time\n",
    "print(f'{predict_time}s')\n",
    "print(tracemalloc.get_traced_memory())\n",
    "tracemalloc.stop()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.01088213920593s\n",
      "(4885159, 5708880)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Paro, Nacional, ay, est叩, lindo, el, paro, No...</td>\n",
       "      <td>[Paro, Nacional, ay, estar, lindar, el, parir,...</td>\n",
       "      <td>[I-ORG, I-LOC, I-LOC, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[La, gente, sabe, !, !, La, gente, entiende, !...</td>\n",
       "      <td>[La, gente, saber, !, !, La, gente, entender, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[臓, Que, belleza, !, Deja, ordenando, que, le,...</td>\n",
       "      <td>[臓, Que, belleza, !, Deja, ordenar, que, le, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Guillermo, Lasso, Si, ,, pero, vaya, a, la, A...</td>\n",
       "      <td>[Guillermo, Lasso, Si, ,, pero, ir, a, lo, Asa...</td>\n",
       "      <td>[I-PER, I-PER, I-PER, O, O, O, O, O, I-ORG, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Tan, falsa, esta, nota, ,, porque, el, pasado...</td>\n",
       "      <td>[Tan, falso, este, noto, ,, porque, el, pasar,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [Paro, Nacional, ay, est叩, lindo, el, paro, No...   \n",
       "1  [La, gente, sabe, !, !, La, gente, entiende, !...   \n",
       "2  [臓, Que, belleza, !, Deja, ordenando, que, le,...   \n",
       "3  [Guillermo, Lasso, Si, ,, pero, vaya, a, la, A...   \n",
       "4  [Tan, falsa, esta, nota, ,, porque, el, pasado...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [Paro, Nacional, ay, estar, lindar, el, parir,...   \n",
       "1  [La, gente, saber, !, !, La, gente, entender, ...   \n",
       "2  [臓, Que, belleza, !, Deja, ordenar, que, le, a...   \n",
       "3  [Guillermo, Lasso, Si, ,, pero, ir, a, lo, Asa...   \n",
       "4  [Tan, falso, este, noto, ,, porque, el, pasar,...   \n",
       "\n",
       "                                         predictions  \n",
       "0   [I-ORG, I-LOC, I-LOC, O, O, O, O, O, O, O, O, O]  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [I-PER, I-PER, I-PER, O, O, O, O, O, I-ORG, I-...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_2 = pd.concat([tweets,tweets])\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "tweets_2['predictions'] = tweets_2['lemmas'].apply(predict_from_list)\n",
    "predict_time = time.time() - start_time\n",
    "print(f'{predict_time}s')\n",
    "print(tracemalloc.get_traced_memory())\n",
    "tracemalloc.stop()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212.3076093196869s\n",
      "(7331155, 8564586)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Paro, Nacional, ay, est叩, lindo, el, paro, No...</td>\n",
       "      <td>[Paro, Nacional, ay, estar, lindar, el, parir,...</td>\n",
       "      <td>[I-ORG, I-LOC, I-LOC, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[La, gente, sabe, !, !, La, gente, entiende, !...</td>\n",
       "      <td>[La, gente, saber, !, !, La, gente, entender, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[臓, Que, belleza, !, Deja, ordenando, que, le,...</td>\n",
       "      <td>[臓, Que, belleza, !, Deja, ordenar, que, le, a...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Guillermo, Lasso, Si, ,, pero, vaya, a, la, A...</td>\n",
       "      <td>[Guillermo, Lasso, Si, ,, pero, ir, a, lo, Asa...</td>\n",
       "      <td>[I-PER, I-PER, I-PER, O, O, O, O, O, I-ORG, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Tan, falsa, esta, nota, ,, porque, el, pasado...</td>\n",
       "      <td>[Tan, falso, este, noto, ,, porque, el, pasar,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [Paro, Nacional, ay, est叩, lindo, el, paro, No...   \n",
       "1  [La, gente, sabe, !, !, La, gente, entiende, !...   \n",
       "2  [臓, Que, belleza, !, Deja, ordenando, que, le,...   \n",
       "3  [Guillermo, Lasso, Si, ,, pero, vaya, a, la, A...   \n",
       "4  [Tan, falsa, esta, nota, ,, porque, el, pasado...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [Paro, Nacional, ay, estar, lindar, el, parir,...   \n",
       "1  [La, gente, saber, !, !, La, gente, entender, ...   \n",
       "2  [臓, Que, belleza, !, Deja, ordenar, que, le, a...   \n",
       "3  [Guillermo, Lasso, Si, ,, pero, ir, a, lo, Asa...   \n",
       "4  [Tan, falso, este, noto, ,, porque, el, pasar,...   \n",
       "\n",
       "                                         predictions  \n",
       "0   [I-ORG, I-LOC, I-LOC, O, O, O, O, O, O, O, O, O]  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3  [I-PER, I-PER, I-PER, O, O, O, O, O, I-ORG, I-...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_3 = pd.concat([tweets,tweets,tweets])\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "tweets_3['predictions'] = tweets_3['lemmas'].apply(predict_from_list)\n",
    "predict_time = time.time() - start_time\n",
    "print(f'{predict_time}s')\n",
    "print(tracemalloc.get_traced_memory())\n",
    "tracemalloc.stop()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145.80478239059448s\n"
     ]
    }
   ],
   "source": [
    "tweets['predictions'] = tweets['lemmas'].apply(predict_from_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7077"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.pkl', 'wb') as f:\n",
    "    pickle.dump(tweets, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0ys-dRgwJP-r",
    "Ih5d4Z_oLURD"
   ],
   "name": "NER_tesis_wikiner.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('Tesis': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "74a7d882c2bcd5ee891de00319dc96d035102b2fcbefebca01a2b31dd177b1ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
